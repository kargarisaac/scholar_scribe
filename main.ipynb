{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaackargar/anaconda3/envs/LLMs/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Elasticsearch client\n",
    "es = Elasticsearch([\"http://localhost:9200\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaackargar/anaconda3/envs/LLMs/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize Sentence Transformer model\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_if_not_exists(index_name: str):\n",
    "    if es.indices.exists(index=index_name):\n",
    "        print(f\"Index '{index_name}' exists. Deleting it...\")\n",
    "        es.indices.delete(index=index_name)\n",
    "    \n",
    "    print(f\"Creating new index '{index_name}'...\")\n",
    "    mapping = {\n",
    "        'mappings': {\n",
    "            'properties': {\n",
    "                'paper_id': {'type': 'keyword'},\n",
    "                'chunk_id': {'type': 'integer'},\n",
    "                'title': {'type': 'text'},\n",
    "                'text': {'type': 'text'},\n",
    "                'embedding': {\n",
    "                    'type': 'dense_vector',\n",
    "                    'dims': 384,\n",
    "                    'index': True,\n",
    "                    'similarity': 'cosine'\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.create(index=index_name, body=mapping)\n",
    "    print(f\"Index '{index_name}' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'paper_chunks' exists. Deleting it...\n",
      "Creating new index 'paper_chunks'...\n",
      "Index 'paper_chunks' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create index\n",
    "create_index_if_not_exists('paper_chunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(file_path: str) -> str:\n",
    "    with fitz.open(file_path) as doc:\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 35222 characters from the PDF.\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"/Users/isaackargar/Downloads/volker-2023-noncontact.pdf\"\n",
    "text = extract_text_from_pdf(pdf_path)\n",
    "print(f\"Extracted {len(text)} characters from the PDF.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text: str, max_length: int = 500) -> List[str]:\n",
    "    sentences = text.split('. ')\n",
    "    chunks = []\n",
    "    current_chunk = ''\n",
    "    for sentence in sentences:\n",
    "        if len(current_chunk) + len(sentence) + 1 <= max_length:\n",
    "            current_chunk += sentence + '. '\n",
    "        else:\n",
    "            chunks.append(current_chunk.strip())\n",
    "            current_chunk = sentence + '. '\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 87 chunks from the text.\n"
     ]
    }
   ],
   "source": [
    "# Chunk the text\n",
    "chunks = chunk_text(text, max_length=500)\n",
    "print(f\"Created {len(chunks)} chunks from the text.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_chunks(paper_id: str, title: str, chunks: List[str]):\n",
    "    actions = []\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        embedding = embedder.encode(chunk)\n",
    "        doc = {\n",
    "            'paper_id': paper_id,\n",
    "            'chunk_id': idx,\n",
    "            'title': title,\n",
    "            'text': chunk,\n",
    "            'embedding': embedding.tolist()\n",
    "        }\n",
    "        action = {\n",
    "            \"_index\": \"paper_chunks\",\n",
    "            \"_id\": f\"{paper_id}_{idx}\",\n",
    "            \"_source\": doc\n",
    "        }\n",
    "        actions.append(action)\n",
    "    bulk(es, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks indexed in Elasticsearch.\n"
     ]
    }
   ],
   "source": [
    "# Index the chunks\n",
    "paper_id = pdf_path.split(\"/\")[-1].split(\".\")[0]\n",
    "title = pdf_path.split(\"/\")[-1].split(\".\")[0]\n",
    "index_chunks(paper_id, title, chunks)\n",
    "print(\"Chunks indexed in Elasticsearch.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_similar_chunks(query: str, top_k: int = 5):\n",
    "    query_embedding = embedder.encode(query)\n",
    "    # Normalize the embedding\n",
    "    query_vector = query_embedding / np.linalg.norm(query_embedding)\n",
    "    script_query = {\n",
    "        \"script_score\": {\n",
    "            \"query\": {\"match_all\": {}},\n",
    "            \"script\": {\n",
    "                # Use max() to ensure non-negative scores\n",
    "                \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n",
    "                \"params\": {\"query_vector\": query_vector.tolist()}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es.search(\n",
    "        index=\"paper_chunks\",\n",
    "        body={\n",
    "            \"size\": top_k,\n",
    "            \"query\": script_query,\n",
    "            \"_source\": {\"includes\": [\"paper_id\", \"chunk_id\", \"title\", \"text\"]}\n",
    "        }\n",
    "    )\n",
    "    return response['hits']['hits']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 similar chunks for query 'How this paper tries to solve NDT? Tell me in detail':\n",
      "\n",
      "Chunk 1:\n",
      "6, NOVEMBER 2023\n",
      "Transactions of the ASME\n",
      "Downloaded from http://asmedigitalcollection.asme.org/nondestructive/article-pdf/6/4/041002/6992491/nde_6_4_041002.pdf by guest on 05 March 2023\n",
      "amount of time.\n",
      "---\n",
      "\n",
      "Chunk 2:\n",
      "7\n",
      "Lay-up\n",
      "Thickness (mm)\n",
      "5/4\n",
      "3.05\n",
      "4/3\n",
      "2.4\n",
      "3/2\n",
      "1.74\n",
      "2/1\n",
      "1.05\n",
      "Table 2\n",
      "Artiﬁcial defect dimensions corresponding to the\n",
      "GLARE 2 material in Fig. 7\n",
      "Defect ID\n",
      "Design diameter (mm)\n",
      "1, 6, 7\n",
      "3\n",
      "2, 5, 8\n",
      "6\n",
      "3, 4, 9\n",
      "12\n",
      "041002-4 / Vol. 6, NOVEMBER 2023\n",
      "Transactions of the ASME\n",
      "Downloaded from http://asmedigitalcollection.asme.org/nondestructive/article-pdf/6/4/041002/6992491/nde_6_4_041002.pdf by guest on 05 March 2023\n",
      "Fig. 6\n",
      "Veriﬁcation of scaling rule of the dispersion curve\n",
      "Fig.\n",
      "---\n",
      "\n",
      "Chunk 3:\n",
      "The ﬁnite-difference scheme is based on a\n",
      "rotated staggered grid. In the case of anisotropy, it is known that\n",
      "a rotated staggered grid provides better results compared to stag-\n",
      "gered grids, where numerical artifacts are introduced because differ-\n",
      "ences over boundaries are not properly taken into account [25]. The\n",
      "panel is built up by applying a tensor rotation related to the lay-up.\n",
      "The total simulation time is 120 ms, with a time sampling of about\n",
      "3 ns.\n",
      "---\n",
      "\n",
      "Chunk 4:\n",
      "The C-scan shows the transmission amplitude on a logarithmic scale,\n",
      "and the thickest part has the highest attenuation. The DVM result shows the actual thickness at the depth of the defects below\n",
      "the surface. The values of the actual thickness at eight point locations are given including four defect locations corresponding\n",
      "to the defects given in Fig. 7(a).\n",
      "Journal of Nondestructive Evaluation, Diagnostics\n",
      "and Prognostics of Engineering Systems\n",
      "NOVEMBER 2023, Vol.\n",
      "---\n",
      "\n",
      "Chunk 5:\n",
      "The elastic properties of the material\n",
      "are taken from Ochoa [24]. The dispersion curve was calculated\n",
      "as a function of propagation direction and frequency (see\n",
      "Fig. 8(b)). There is clearly a measurable amount of anisotropy in\n",
      "the frequency range of interest, with phase velocity variations in\n",
      "the order of 100 m/s. The measured phase velocity is compared to\n",
      "a numerical 3D ﬁnite-difference modeling result, where each ply\n",
      "is included separately.\n",
      "---\n",
      "\n",
      "Chunk 6:\n",
      "In the most\n",
      "general case, the dispersion curve is a function of frequency and\n",
      "propagation direction in case of signiﬁcant anisotropy.\n",
      "---\n",
      "\n",
      "Chunk 7:\n",
      "H., and Bohlen, T., 2004, “Finite-Difference Modeling of\n",
      "Viscoelastic and Anisotropic Wave Propagation Using the Rotated Staggered\n",
      "Grid,” Geophysics, 69(2), pp. 583–591.\n",
      "041002-8 / Vol. 6, NOVEMBER 2023\n",
      "Transactions of the ASME\n",
      "Downloaded from http://asmedigitalcollection.asme.org/nondestructive/article-pdf/6/4/041002/6992491/nde_6_4_041002.pdf by guest on 05 March 2023\n",
      ".\n",
      "---\n",
      "\n",
      "Chunk 8:\n",
      "7(a), a cross-section\n",
      "of the material is given with a selection of Teﬂon inserts in each\n",
      "conﬁguration. Three sets of nine artiﬁcial defects (Teﬂon inserts)\n",
      "are embedded in each conﬁguration. The depth and diameter of\n",
      "these defects vary. Table 2 provides an overview of the defect\n",
      "sizes present in this sample.\n",
      "Figure 7(b) shows a conventional ultrasonic transmission C-scan\n",
      "using a 5-MHz ultrasonic transducer.\n",
      "---\n",
      "\n",
      "Chunk 9:\n",
      "The angular frequency is denoted by\n",
      "ω, c is the speed of sound in air, and Δz is the distance between\n",
      "the two planes. The horizontal wavenumbers in the x- and\n",
      "y-directions are indicated by kx and ky, respectively\n",
      "The Rayleigh II integral must be used if the composite panel is\n",
      "not ﬂat or non-parallel with the scan plane.\n",
      "---\n",
      "\n",
      "Chunk 10:\n",
      "As a result of\n",
      "Eq. (3), the required aperture of the scan area scales up with increas-\n",
      "ing stand-off distance. Moreover, the sensitivity differences\n",
      "between the MEMS sensors need to be corrected before back-\n",
      "propagation. The calibration consists of a scan in the length direc-\n",
      "tion of the array, where the scan step size equals the pitch of the\n",
      "array.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Test search\n",
    "test_query = \"How this paper tries to solve NDT? Tell me in detail\"\n",
    "similar_chunks = search_similar_chunks(test_query, top_k=10)\n",
    "print(f\"\\nTop 3 similar chunks for query '{test_query}':\")\n",
    "for i, hit in enumerate(similar_chunks):\n",
    "    source = hit['_source']\n",
    "    print(f\"\\nChunk {i+1}:\")\n",
    "    print(source['text'])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Answer:\n",
      "The paper addresses Non-Destructive Testing (NDT) by employing a combination of advanced simulation techniques and practical ultrasonic testing methods to detect and characterize defects in composite materials, specifically GLARE 2 material. Here are the detailed approaches outlined in the excerpts:\n",
      "\n",
      "1. **Finite-Difference Modeling**: The authors utilize a finite-difference scheme based on a rotated staggered grid, which is particularly advantageous for handling anisotropic materials. This method minimizes numerical artifacts that can arise from improper boundary handling, enhancing the accuracy of the simulation results. The approach includes a tensor rotation that corresponds to the lay-up of the composite, allowing for a more precise modeling of wave propagation through the material.\n",
      "\n",
      "2. **Dispersion Curve Analysis**: The paper calculates dispersion curves as functions of frequency and propagation direction, highlighting the measurable anisotropy within the material. This analysis is crucial for understanding how waves propagate through the composite and assists in predicting how defects will affect wave transmission.\n",
      "\n",
      "3. **Ultrasonic Testing**: The researchers employ conventional ultrasonic transmission methods, using a 5-MHz ultrasonic transducer to perform C-scan imaging. This technique visualizes the transmission amplitude of ultrasonic waves through the material, allowing for the identification of defects based on variations in signal attenuation.\n",
      "\n",
      "4. **Defect Characterization**: The study incorporates artificial defects of varying sizes (as detailed in Table 2) to test the effectiveness of the NDT methods. The C-scan results and additional measurements provide insights into the actual thickness of the material at defect locations, enabling the quantification and characterization of defects.\n",
      "\n",
      "5. **Calibration and Sensitivity Adjustment**: The paper discusses the need for calibration of MEMS sensors used in the testing process, which involves adjusting for sensitivity differences among the sensors and ensuring accurate back-propagation of the signals. This step is critical for maintaining the integrity of the measurements and enhancing the reliability of the defect detection process.\n",
      "\n",
      "By integrating these methodologies, the paper aims to improve the effectiveness and accuracy of NDT for composite materials, facilitating better defect detection and assessment in engineering applications.\n"
     ]
    }
   ],
   "source": [
    "# Test OpenAI integration (if you want to include this part)\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "    # Prepare the prompt (you can modify this as needed)\n",
    "    relevant_texts = [hit['_source']['text'] for hit in similar_chunks]\n",
    "    combined_text = \"\\n\\n\".join(relevant_texts)\n",
    "    prompt = f\"\"\"You are an expert assistant. Based on the following excerpts from a research paper, answer the question concisely and accurately.\n",
    "\n",
    "Question: {test_query}\n",
    "\n",
    "Excerpts:\n",
    "{combined_text}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # Make sure to use an available model\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=2000,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    print(\"\\nGenerated Answer:\")\n",
    "    print(answer)\n",
    "except Exception as e:\n",
    "    print(f\"Error generating answer: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
